{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from scipy.ndimage import gaussian_filter,median_filter\n",
    "from skimage import morphology\n",
    "from skimage.restoration import denoise_tv_chambolle,denoise_wavelet,denoise_bilateral, estimate_sigma,denoise_nl_means\n",
    "def exponential_decay(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "def load_tiff_data(file_path):\n",
    "    with tiff.TiffFile(file_path) as tif:\n",
    "        images = tif.asarray()\n",
    "        return images\n",
    "\n",
    "\n",
    "def bin_by_intensity(images, frames,n_bins=1,):\n",
    "    initial_intensity = np.mean(images[0:frames, :, :],axis = 0)  \n",
    "    \n",
    "    quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "    bins = np.quantile(initial_intensity, quantiles)\n",
    "    \n",
    "    bin_indices = np.digitize(initial_intensity, bins) - 1\n",
    "    bin_indices[bin_indices == n_bins] = n_bins - 1\n",
    "    \n",
    "    return bin_indices, bins\n",
    "def fit_exponential_models(images, bin_indices, bins,frames):\n",
    "    time_points = np.arange(frames)\n",
    "    models = []\n",
    "    for i in range(len(bins)-1):\n",
    "        mask = bin_indices == i\n",
    "        if np.any(mask):\n",
    "            mean_decay_curve = np.mean(images[:frames, mask], axis=1)\n",
    "            params, _ = curve_fit(exponential_decay, time_points, mean_decay_curve, p0=[mean_decay_curve.max(), 0.1, mean_decay_curve.min()],maxfev=10000)\n",
    "            models.append((params, mask))\n",
    "    return models\n",
    "def apply_correction(images, models):\n",
    "    corrected_images = np.copy(images).astype(np.float64)\n",
    "    for params, mask in models:\n",
    "        corrected_images[:, mask] = (images[:, mask] - np.expand_dims(exponential_decay(np.arange(images.shape[0]),params[0],params[1],params[2]),-1))/np.mean(images[0:5,:,:])\n",
    "    return corrected_images\n",
    "\n",
    "def process_tif(file_path,frames,n_bins):\n",
    "    images = load_tiff_data(file_path)[5:]\n",
    "\n",
    "    bin_indices, bins = bin_by_intensity(images,frames,n_bins = n_bins)\n",
    "    models = fit_exponential_models(images, bin_indices, bins,frames)\n",
    "    corrected_images = apply_correction(images, models)\n",
    "    ##uncomment for visualization\n",
    "    # cmap = \"jet\"\n",
    "    # min_val = 0.003\n",
    "    # max_val = 0.015\n",
    "    # plt.imshow(denoise_tv_chambolle(np.mean(corrected_images[61:66,:,:],axis = 0),weight = 0.1),vmin = min_val,vmax = max_val,cmap = cmap)\n",
    "    return np.mean(corrected_images,axis = (1,2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_directory = r\"E:\\data\\theta\\calcium\\averaging\"\n",
    "n_bins = 100\n",
    "df = pd.DataFrame([],columns = [\"abf\",\"date\",\"rep\",\"condition\",\"data\"])\n",
    "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.tif'):\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            split_path = filename.lower().split(\"_\")\n",
    "            df.loc[len(df)] = [split_path[-4],split_path[-4][:-3],int(split_path[-2][1]),split_path[-1].split(\".\")[0],process_tif(full_path,59,n_bins)]\n",
    "df.to_csv(f\"{n_bins} bins raw.csv\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.stats import sem\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Seed for reproducibility\n",
    "random.seed(123)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(f\"{n_bins} bins raw.csv\")\n",
    "color_dict = {\n",
    "    \"baseline\": \"black\",\n",
    "    \"cnqx\": \"orange\",\n",
    "    \"cnqxwash\": \"gray\",\n",
    "    \"rnbaseline\": \"black\",\n",
    "    \"rnon\": \"red\",\n",
    "    \"rnwash\": \"gray\",\n",
    "}\n",
    "\n",
    "condition_lst = [\"baseline\", \"cnqx\", \"cnqxwash\", \"rnbaseline\", \"rn1734\", \"rnwash\"]\n",
    "color_lst = [\"black\", \"orange\", \"gray\", \"black\", \"red\", \"gray\"]\n",
    "days = len(df[\"date\"].unique())\n",
    "arr = np.empty((6, days))\n",
    "df[\"condition\"] = df[\"condition\"].replace(\"rn1734\", \"rnon\")\n",
    "df = df[df['condition'] != 'txred']\n",
    "\n",
    "# Process each date\n",
    "for date_idx, (date, group) in enumerate(df.groupby(\"date\")):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(5, 10))\n",
    "    for cond_idx, (condition, cond_group) in enumerate(group.groupby(\"condition\")):\n",
    "        cond_group = cond_group[cond_group[\"rep\"] == cond_group[\"rep\"].max()]\n",
    "        data = cond_group[\"data\"].iloc[0].replace(\"  \", \" \")\n",
    "        data = data.replace(\" \", \",\")\n",
    "        data = data[0] + data[2:]\n",
    "        data = data.replace(\",,\", \",\")\n",
    "        data = ast.literal_eval(data)\n",
    "        x_values = np.array(range(len(data))) / 12.84\n",
    "        smoothed_segment = uniform_filter1d(data[61:74], size=9)\n",
    "        arr[cond_idx, date_idx] = max(np.max(smoothed_segment) + np.min(smoothed_segment), 0)\n",
    "\n",
    "        # Plot\n",
    "        if condition in [\"baseline\", \"cnqx\", \"cnqxwash\"]:\n",
    "            ax[0].plot(x_values, data, color=color_dict[condition], lw=1)\n",
    "            ax[0].axvline(59 / 12.84, lw=0.5, color=\"black\", linestyle=\"dashed\")\n",
    "            ax[0].set_xlabel(\"Time(s)\")\n",
    "            ax[0].set_ylabel(\"DF/F\")\n",
    "        elif condition in [\"rnbaseline\", \"rnon\", \"rnwash\"]:\n",
    "            ax[1].plot(x_values, data, color=color_dict[condition], lw=1)\n",
    "            ax[1].axvline(59 / 12.84, lw=0.5, color=\"black\", linestyle=\"dashed\")\n",
    "            ax[1].axvline(70 / 12.84, lw=0.5, color=\"black\", linestyle=\"dashed\")\n",
    "            ax[1].set_xlabel(\"Time(s)\")\n",
    "            ax[1].set_ylabel(\"DF/F\")\n",
    "        else:\n",
    "            print(condition)\n",
    "            continue\n",
    "    plt.title(date)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{date}.svg\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "arr[:3, :] = arr[:3, :] / arr[0, :]\n",
    "arr[3:6, :] = arr[3:6, :] / arr[3, :]\n",
    "\n",
    "\n",
    "def plot_gradient_line(x1, y1, x2, y2, color_start, color_end, steps=10):\n",
    "    color_start_rgba = np.array(mcolors.to_rgba(color_start))\n",
    "    color_end_rgba = np.array(mcolors.to_rgba(color_end))\n",
    "    \n",
    "    for i in range(steps):\n",
    "        xi = x1 + (x2 - x1) * i / steps\n",
    "        yi = y1 + (y2 - y1) * i / steps\n",
    "        xi_next = x1 + (x2 - x1) * (i + 1) / steps\n",
    "        yi_next = y1 + (y2 - y1) * (i + 1) / steps\n",
    "        color = color_start_rgba * (1 - i / steps) + color_end_rgba * (i / steps)\n",
    "        \n",
    "        plt.plot([xi, xi_next], [yi, yi_next], color=color,lw = 1)\n",
    "\n",
    "\n",
    "scatter_points_cnqx = []\n",
    "for idx in range(3):\n",
    "    data = arr[idx, :]\n",
    "    x_values = [idx + random.uniform(-0.15, 0.15) for x in range(len(data))]\n",
    "    plt.bar(condition_lst[idx], np.mean(data), edgecolor=color_lst[idx], yerr=sem(data), alpha=0.5, ecolor=color_lst[idx], capsize=5,fill = False)\n",
    "    scatter_points = plt.scatter(x_values, data, color=color_lst[idx])\n",
    "    scatter_points_cnqx.append((x_values, data))\n",
    "\n",
    "\n",
    "for i in range(len(scatter_points_cnqx) - 1):\n",
    "    for j in range(len(scatter_points_cnqx[i][0])):\n",
    "        x1, y1 = scatter_points_cnqx[i][0][j], scatter_points_cnqx[i][1][j]\n",
    "        x2, y2 = scatter_points_cnqx[i + 1][0][j], scatter_points_cnqx[i + 1][1][j]\n",
    "        plot_gradient_line(x1, y1, x2, y2, color_lst[i], color_lst[i + 1])\n",
    "\n",
    "plt.savefig(\"raw_bar_cnqx_gradient.svg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "scatter_points_rn = []\n",
    "for idx in range(3, 6):\n",
    "    data = arr[idx, :]\n",
    "    x_values = [idx - 3 + random.uniform(-0.15, 0.15) for x in range(len(data))]\n",
    "    plt.bar(condition_lst[idx], np.mean(data), edgecolor=color_lst[idx], yerr=sem(data), alpha=0.5, ecolor=color_lst[idx], capsize=5, fill = False,lw = 1)\n",
    "    scatter_points = plt.scatter(x_values, data, color=color_lst[idx])\n",
    "    scatter_points_rn.append((x_values, data))\n",
    "\n",
    "\n",
    "for i in range(len(scatter_points_rn) - 1):\n",
    "    for j in range(len(scatter_points_rn[i][0])):\n",
    "        x1, y1 = scatter_points_rn[i][0][j], scatter_points_rn[i][1][j]\n",
    "        x2, y2 = scatter_points_rn[i + 1][0][j], scatter_points_rn[i + 1][1][j]\n",
    "        plot_gradient_line(x1, y1, x2, y2, color_lst[i + 3], color_lst[i + 4])\n",
    "\n",
    "plt.savefig(\"raw_bar_rn_gradient.svg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import  wilcoxon, sem\n",
    "print(\"cnqxbase\",np.mean(arr[0,:]),sem(arr[0,:]),\"vs\",np.mean(arr[1,:]),sem(arr[1,:]),\"stats\",wilcoxon(arr[0,:],arr[1,:]))\n",
    "print(\"cnqxwash\",np.mean(arr[2,:]),sem(arr[2,:]),\"vs\",np.mean(arr[1,:]),sem(arr[1,:]),\"stats\",wilcoxon(arr[2,:],arr[1,:]))\n",
    "print(\"rnbase\",np.mean(arr[3,:]),sem(arr[3,:]),\"vs\",np.mean(arr[4,:]),sem(arr[4,:]),\"stats\",wilcoxon(arr[3,:],arr[4,:]))\n",
    "print(\"rnwash\",np.mean(arr[5,:]),sem(arr[5,:]),\"vs\",np.mean(arr[4,:]),sem(arr[4,:]),\"stats\",wilcoxon(arr[5,:],arr[4,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
